<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_8imvyvbshr1d-6>li{counter-increment:lst-ctn-kix_8imvyvbshr1d-6}ol.lst-kix_hd3j599mwgvy-4.start{counter-reset:lst-ctn-kix_hd3j599mwgvy-4 0}ul.lst-kix_vbm6i0fpibou-0{list-style-type:none}ul.lst-kix_vbm6i0fpibou-1{list-style-type:none}ul.lst-kix_vbm6i0fpibou-2{list-style-type:none}ul.lst-kix_vbm6i0fpibou-3{list-style-type:none}ul.lst-kix_vbm6i0fpibou-4{list-style-type:none}ul.lst-kix_vbm6i0fpibou-5{list-style-type:none}ul.lst-kix_vbm6i0fpibou-6{list-style-type:none}ul.lst-kix_vbm6i0fpibou-7{list-style-type:none}ul.lst-kix_vbm6i0fpibou-8{list-style-type:none}.lst-kix_hd3j599mwgvy-4>li{counter-increment:lst-ctn-kix_hd3j599mwgvy-4}ol.lst-kix_8imvyvbshr1d-5.start{counter-reset:lst-ctn-kix_8imvyvbshr1d-5 0}.lst-kix_hd3j599mwgvy-6>li{counter-increment:lst-ctn-kix_hd3j599mwgvy-6}.lst-kix_hd3j599mwgvy-0>li{counter-increment:lst-ctn-kix_hd3j599mwgvy-0}.lst-kix_b8qdaap7ttdm-3>li:before{content:"-  "}.lst-kix_8imvyvbshr1d-4>li{counter-increment:lst-ctn-kix_8imvyvbshr1d-4}.lst-kix_b8qdaap7ttdm-2>li:before{content:"-  "}.lst-kix_b8qdaap7ttdm-4>li:before{content:"-  "}ol.lst-kix_hd3j599mwgvy-5.start{counter-reset:lst-ctn-kix_hd3j599mwgvy-5 0}.lst-kix_b8qdaap7ttdm-0>li:before{content:"-  "}.lst-kix_nvsh1jp4hufk-4>li:before{content:"-  "}.lst-kix_b8qdaap7ttdm-1>li:before{content:"-  "}.lst-kix_nvsh1jp4hufk-5>li:before{content:"-  "}.lst-kix_tbtkw0ll1bh6-6>li:before{content:"-  "}.lst-kix_nvsh1jp4hufk-7>li:before{content:"-  "}.lst-kix_tbtkw0ll1bh6-5>li:before{content:"-  "}.lst-kix_tbtkw0ll1bh6-7>li:before{content:"-  "}.lst-kix_nvsh1jp4hufk-6>li:before{content:"-  "}.lst-kix_nvsh1jp4hufk-8>li:before{content:"-  "}.lst-kix_tbtkw0ll1bh6-2>li:before{content:"-  "}ol.lst-kix_8imvyvbshr1d-4.start{counter-reset:lst-ctn-kix_8imvyvbshr1d-4 0}.lst-kix_tbtkw0ll1bh6-1>li:before{content:"-  "}.lst-kix_b8qdaap7ttdm-6>li:before{content:"-  "}.lst-kix_tbtkw0ll1bh6-0>li:before{content:"-  "}.lst-kix_b8qdaap7ttdm-5>li:before{content:"-  "}ul.lst-kix_2k4s0v6z4nqo-7{list-style-type:none}.lst-kix_tbtkw0ll1bh6-8>li:before{content:"-  "}ul.lst-kix_2k4s0v6z4nqo-8{list-style-type:none}.lst-kix_b8qdaap7ttdm-7>li:before{content:"-  "}.lst-kix_tbtkw0ll1bh6-3>li:before{content:"-  "}.lst-kix_b8qdaap7ttdm-8>li:before{content:"-  "}.lst-kix_tbtkw0ll1bh6-4>li:before{content:"-  "}.lst-kix_2k4s0v6z4nqo-0>li:before{content:"\0025cf   "}.lst-kix_2k4s0v6z4nqo-2>li:before{content:"\0025a0   "}.lst-kix_2k4s0v6z4nqo-6>li:before{content:"\0025cf   "}ol.lst-kix_8imvyvbshr1d-3.start{counter-reset:lst-ctn-kix_8imvyvbshr1d-3 0}.lst-kix_8imvyvbshr1d-0>li:before{content:"" counter(lst-ctn-kix_8imvyvbshr1d-0,decimal) ". "}ul.lst-kix_2k4s0v6z4nqo-5{list-style-type:none}ul.lst-kix_2k4s0v6z4nqo-6{list-style-type:none}.lst-kix_tdvx3axora8l-6>li:before{content:"-  "}ul.lst-kix_2k4s0v6z4nqo-3{list-style-type:none}ul.lst-kix_2k4s0v6z4nqo-4{list-style-type:none}ul.lst-kix_2k4s0v6z4nqo-1{list-style-type:none}ul.lst-kix_2k4s0v6z4nqo-2{list-style-type:none}ul.lst-kix_2k4s0v6z4nqo-0{list-style-type:none}.lst-kix_tdvx3axora8l-8>li:before{content:"-  "}.lst-kix_2k4s0v6z4nqo-4>li:before{content:"\0025cb   "}.lst-kix_hd3j599mwgvy-1>li:before{content:"" counter(lst-ctn-kix_hd3j599mwgvy-1,lower-latin) ". "}.lst-kix_hd3j599mwgvy-3>li:before{content:"" counter(lst-ctn-kix_hd3j599mwgvy-3,decimal) ". "}ul.lst-kix_b8qdaap7ttdm-0{list-style-type:none}.lst-kix_nvsh1jp4hufk-3>li:before{content:"-  "}.lst-kix_8imvyvbshr1d-8>li:before{content:"" counter(lst-ctn-kix_8imvyvbshr1d-8,lower-roman) ". "}ul.lst-kix_b8qdaap7ttdm-1{list-style-type:none}.lst-kix_hd3j599mwgvy-5>li:before{content:"" counter(lst-ctn-kix_hd3j599mwgvy-5,lower-roman) ". "}ul.lst-kix_b8qdaap7ttdm-2{list-style-type:none}ul.lst-kix_b8qdaap7ttdm-3{list-style-type:none}ul.lst-kix_b8qdaap7ttdm-4{list-style-type:none}.lst-kix_nvsh1jp4hufk-1>li:before{content:"-  "}ul.lst-kix_b8qdaap7ttdm-5{list-style-type:none}ul.lst-kix_b8qdaap7ttdm-6{list-style-type:none}ul.lst-kix_b8qdaap7ttdm-7{list-style-type:none}.lst-kix_k8ew8v9e5c7-0>li:before{content:"-  "}.lst-kix_k8ew8v9e5c7-2>li:before{content:"-  "}.lst-kix_2k4s0v6z4nqo-8>li:before{content:"\0025a0   "}.lst-kix_8imvyvbshr1d-6>li:before{content:"" counter(lst-ctn-kix_8imvyvbshr1d-6,decimal) ". "}.lst-kix_8imvyvbshr1d-2>li:before{content:"" counter(lst-ctn-kix_8imvyvbshr1d-2,lower-roman) ". "}.lst-kix_8imvyvbshr1d-0>li{counter-increment:lst-ctn-kix_8imvyvbshr1d-0}ol.lst-kix_hd3j599mwgvy-6.start{counter-reset:lst-ctn-kix_hd3j599mwgvy-6 0}.lst-kix_8imvyvbshr1d-4>li:before{content:"" counter(lst-ctn-kix_8imvyvbshr1d-4,lower-latin) ". "}.lst-kix_k8ew8v9e5c7-8>li:before{content:"-  "}.lst-kix_k8ew8v9e5c7-4>li:before{content:"-  "}.lst-kix_w5w7l1qd8d42-6>li:before{content:"-  "}ul.lst-kix_b8qdaap7ttdm-8{list-style-type:none}.lst-kix_w5w7l1qd8d42-4>li:before{content:"-  "}.lst-kix_w5w7l1qd8d42-8>li:before{content:"-  "}.lst-kix_hd3j599mwgvy-7>li:before{content:"" counter(lst-ctn-kix_hd3j599mwgvy-7,lower-latin) ". "}ol.lst-kix_8imvyvbshr1d-1.start{counter-reset:lst-ctn-kix_8imvyvbshr1d-1 0}.lst-kix_k8ew8v9e5c7-6>li:before{content:"-  "}.lst-kix_oykm236axc8s-3>li:before{content:"-  "}.lst-kix_w5w7l1qd8d42-0>li:before{content:"-  "}.lst-kix_oykm236axc8s-1>li:before{content:"-  "}.lst-kix_oykm236axc8s-5>li:before{content:"-  "}ol.lst-kix_hd3j599mwgvy-8.start{counter-reset:lst-ctn-kix_hd3j599mwgvy-8 0}.lst-kix_w5w7l1qd8d42-2>li:before{content:"-  "}.lst-kix_oykm236axc8s-7>li:before{content:"-  "}.lst-kix_hd3j599mwgvy-8>li{counter-increment:lst-ctn-kix_hd3j599mwgvy-8}.lst-kix_vbm6i0fpibou-7>li:before{content:"-  "}.lst-kix_tdvx3axora8l-4>li:before{content:"-  "}ol.lst-kix_8imvyvbshr1d-0.start{counter-reset:lst-ctn-kix_8imvyvbshr1d-0 0}.lst-kix_hd3j599mwgvy-2>li{counter-increment:lst-ctn-kix_hd3j599mwgvy-2}.lst-kix_vbm6i0fpibou-3>li:before{content:"-  "}.lst-kix_tdvx3axora8l-0>li:before{content:"-  "}.lst-kix_tdvx3axora8l-2>li:before{content:"-  "}.lst-kix_vbm6i0fpibou-5>li:before{content:"-  "}ol.lst-kix_hd3j599mwgvy-7.start{counter-reset:lst-ctn-kix_hd3j599mwgvy-7 0}.lst-kix_vbm6i0fpibou-2>li:before{content:"-  "}.lst-kix_vbm6i0fpibou-0>li:before{content:"-  "}.lst-kix_vbm6i0fpibou-1>li:before{content:"-  "}.lst-kix_hd3j599mwgvy-3>li{counter-increment:lst-ctn-kix_hd3j599mwgvy-3}.lst-kix_8imvyvbshr1d-5>li{counter-increment:lst-ctn-kix_8imvyvbshr1d-5}ol.lst-kix_8imvyvbshr1d-7{list-style-type:none}ol.lst-kix_8imvyvbshr1d-6{list-style-type:none}ol.lst-kix_8imvyvbshr1d-8{list-style-type:none}ol.lst-kix_8imvyvbshr1d-3{list-style-type:none}ol.lst-kix_8imvyvbshr1d-2{list-style-type:none}ol.lst-kix_8imvyvbshr1d-2.start{counter-reset:lst-ctn-kix_8imvyvbshr1d-2 0}ol.lst-kix_8imvyvbshr1d-5{list-style-type:none}ol.lst-kix_8imvyvbshr1d-4{list-style-type:none}ol.lst-kix_hd3j599mwgvy-4{list-style-type:none}ol.lst-kix_hd3j599mwgvy-3{list-style-type:none}ol.lst-kix_hd3j599mwgvy-2{list-style-type:none}ol.lst-kix_hd3j599mwgvy-1{list-style-type:none}ol.lst-kix_hd3j599mwgvy-8{list-style-type:none}ol.lst-kix_hd3j599mwgvy-7{list-style-type:none}ol.lst-kix_hd3j599mwgvy-6{list-style-type:none}ol.lst-kix_hd3j599mwgvy-5{list-style-type:none}ul.lst-kix_oykm236axc8s-1{list-style-type:none}ol.lst-kix_hd3j599mwgvy-0{list-style-type:none}ul.lst-kix_oykm236axc8s-2{list-style-type:none}ul.lst-kix_oykm236axc8s-0{list-style-type:none}ul.lst-kix_nvsh1jp4hufk-1{list-style-type:none}ul.lst-kix_nvsh1jp4hufk-2{list-style-type:none}ul.lst-kix_nvsh1jp4hufk-3{list-style-type:none}ul.lst-kix_nvsh1jp4hufk-4{list-style-type:none}ul.lst-kix_nvsh1jp4hufk-0{list-style-type:none}.lst-kix_hd3j599mwgvy-1>li{counter-increment:lst-ctn-kix_hd3j599mwgvy-1}ol.lst-kix_8imvyvbshr1d-1{list-style-type:none}ol.lst-kix_8imvyvbshr1d-0{list-style-type:none}ul.lst-kix_nvsh1jp4hufk-5{list-style-type:none}ul.lst-kix_nvsh1jp4hufk-6{list-style-type:none}.lst-kix_hd3j599mwgvy-7>li{counter-increment:lst-ctn-kix_hd3j599mwgvy-7}ul.lst-kix_w5w7l1qd8d42-0{list-style-type:none}ul.lst-kix_nvsh1jp4hufk-7{list-style-type:none}ul.lst-kix_nvsh1jp4hufk-8{list-style-type:none}ul.lst-kix_w5w7l1qd8d42-2{list-style-type:none}ul.lst-kix_w5w7l1qd8d42-1{list-style-type:none}ul.lst-kix_w5w7l1qd8d42-4{list-style-type:none}ul.lst-kix_w5w7l1qd8d42-3{list-style-type:none}ul.lst-kix_w5w7l1qd8d42-6{list-style-type:none}ul.lst-kix_w5w7l1qd8d42-5{list-style-type:none}ul.lst-kix_w5w7l1qd8d42-8{list-style-type:none}ul.lst-kix_w5w7l1qd8d42-7{list-style-type:none}.lst-kix_8imvyvbshr1d-7>li{counter-increment:lst-ctn-kix_8imvyvbshr1d-7}ul.lst-kix_k8ew8v9e5c7-0{list-style-type:none}ul.lst-kix_k8ew8v9e5c7-1{list-style-type:none}ul.lst-kix_k8ew8v9e5c7-2{list-style-type:none}ul.lst-kix_k8ew8v9e5c7-3{list-style-type:none}ul.lst-kix_k8ew8v9e5c7-4{list-style-type:none}ul.lst-kix_k8ew8v9e5c7-5{list-style-type:none}ul.lst-kix_k8ew8v9e5c7-6{list-style-type:none}ul.lst-kix_k8ew8v9e5c7-7{list-style-type:none}ul.lst-kix_k8ew8v9e5c7-8{list-style-type:none}.lst-kix_2k4s0v6z4nqo-1>li:before{content:"\0025cf   "}.lst-kix_8imvyvbshr1d-1>li:before{content:"" counter(lst-ctn-kix_8imvyvbshr1d-1,lower-latin) ". "}.lst-kix_2k4s0v6z4nqo-7>li:before{content:"\0025cb   "}ol.lst-kix_hd3j599mwgvy-0.start{counter-reset:lst-ctn-kix_hd3j599mwgvy-0 0}ul.lst-kix_tdvx3axora8l-6{list-style-type:none}ul.lst-kix_tdvx3axora8l-5{list-style-type:none}ul.lst-kix_tdvx3axora8l-4{list-style-type:none}ol.lst-kix_8imvyvbshr1d-6.start{counter-reset:lst-ctn-kix_8imvyvbshr1d-6 0}ul.lst-kix_tdvx3axora8l-3{list-style-type:none}ul.lst-kix_tdvx3axora8l-2{list-style-type:none}.lst-kix_tdvx3axora8l-7>li:before{content:"-  "}ul.lst-kix_tdvx3axora8l-1{list-style-type:none}ul.lst-kix_tdvx3axora8l-0{list-style-type:none}.lst-kix_8imvyvbshr1d-1>li{counter-increment:lst-ctn-kix_8imvyvbshr1d-1}.lst-kix_2k4s0v6z4nqo-5>li:before{content:"\0025a0   "}.lst-kix_2k4s0v6z4nqo-3>li:before{content:"\0025cf   "}.lst-kix_hd3j599mwgvy-2>li:before{content:"" counter(lst-ctn-kix_hd3j599mwgvy-2,lower-roman) ". "}.lst-kix_hd3j599mwgvy-0>li:before{content:"" counter(lst-ctn-kix_hd3j599mwgvy-0,decimal) ". "}.lst-kix_hd3j599mwgvy-4>li:before{content:"" counter(lst-ctn-kix_hd3j599mwgvy-4,lower-latin) ". "}.lst-kix_hd3j599mwgvy-6>li:before{content:"" counter(lst-ctn-kix_hd3j599mwgvy-6,decimal) ". "}.lst-kix_nvsh1jp4hufk-2>li:before{content:"-  "}.lst-kix_8imvyvbshr1d-7>li:before{content:"" counter(lst-ctn-kix_8imvyvbshr1d-7,lower-latin) ". "}.lst-kix_8imvyvbshr1d-5>li:before{content:"" counter(lst-ctn-kix_8imvyvbshr1d-5,lower-roman) ". "}.lst-kix_k8ew8v9e5c7-1>li:before{content:"-  "}.lst-kix_nvsh1jp4hufk-0>li:before{content:"-  "}ul.lst-kix_tbtkw0ll1bh6-0{list-style-type:none}ul.lst-kix_tbtkw0ll1bh6-1{list-style-type:none}ul.lst-kix_tbtkw0ll1bh6-2{list-style-type:none}ul.lst-kix_tbtkw0ll1bh6-3{list-style-type:none}ol.lst-kix_hd3j599mwgvy-3.start{counter-reset:lst-ctn-kix_hd3j599mwgvy-3 0}.lst-kix_8imvyvbshr1d-3>li:before{content:"" counter(lst-ctn-kix_8imvyvbshr1d-3,decimal) ". "}.lst-kix_8imvyvbshr1d-3>li{counter-increment:lst-ctn-kix_8imvyvbshr1d-3}ul.lst-kix_oykm236axc8s-5{list-style-type:none}ul.lst-kix_oykm236axc8s-6{list-style-type:none}ul.lst-kix_oykm236axc8s-3{list-style-type:none}ul.lst-kix_oykm236axc8s-4{list-style-type:none}ul.lst-kix_oykm236axc8s-7{list-style-type:none}ul.lst-kix_oykm236axc8s-8{list-style-type:none}ul.lst-kix_tbtkw0ll1bh6-4{list-style-type:none}.lst-kix_k8ew8v9e5c7-5>li:before{content:"-  "}ul.lst-kix_tbtkw0ll1bh6-5{list-style-type:none}ul.lst-kix_tbtkw0ll1bh6-6{list-style-type:none}ul.lst-kix_tbtkw0ll1bh6-7{list-style-type:none}ul.lst-kix_tbtkw0ll1bh6-8{list-style-type:none}.lst-kix_k8ew8v9e5c7-3>li:before{content:"-  "}ol.lst-kix_8imvyvbshr1d-8.start{counter-reset:lst-ctn-kix_8imvyvbshr1d-8 0}.lst-kix_hd3j599mwgvy-8>li:before{content:"" counter(lst-ctn-kix_hd3j599mwgvy-8,lower-roman) ". "}.lst-kix_w5w7l1qd8d42-5>li:before{content:"-  "}.lst-kix_8imvyvbshr1d-8>li{counter-increment:lst-ctn-kix_8imvyvbshr1d-8}.lst-kix_k8ew8v9e5c7-7>li:before{content:"-  "}ol.lst-kix_hd3j599mwgvy-2.start{counter-reset:lst-ctn-kix_hd3j599mwgvy-2 0}.lst-kix_w5w7l1qd8d42-7>li:before{content:"-  "}.lst-kix_oykm236axc8s-4>li:before{content:"-  "}.lst-kix_w5w7l1qd8d42-1>li:before{content:"-  "}ol.lst-kix_hd3j599mwgvy-1.start{counter-reset:lst-ctn-kix_hd3j599mwgvy-1 0}ol.lst-kix_8imvyvbshr1d-7.start{counter-reset:lst-ctn-kix_8imvyvbshr1d-7 0}.lst-kix_oykm236axc8s-0>li:before{content:"-  "}.lst-kix_oykm236axc8s-8>li:before{content:"-  "}.lst-kix_hd3j599mwgvy-5>li{counter-increment:lst-ctn-kix_hd3j599mwgvy-5}.lst-kix_8imvyvbshr1d-2>li{counter-increment:lst-ctn-kix_8imvyvbshr1d-2}.lst-kix_oykm236axc8s-6>li:before{content:"-  "}.lst-kix_vbm6i0fpibou-8>li:before{content:"-  "}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}ul.lst-kix_tdvx3axora8l-8{list-style-type:none}.lst-kix_w5w7l1qd8d42-3>li:before{content:"-  "}ul.lst-kix_tdvx3axora8l-7{list-style-type:none}.lst-kix_tdvx3axora8l-5>li:before{content:"-  "}.lst-kix_vbm6i0fpibou-6>li:before{content:"-  "}.lst-kix_tdvx3axora8l-3>li:before{content:"-  "}.lst-kix_tdvx3axora8l-1>li:before{content:"-  "}.lst-kix_oykm236axc8s-2>li:before{content:"-  "}.lst-kix_vbm6i0fpibou-4>li:before{content:"-  "}ol{margin:0;padding:0}table td,table th{padding:0}.c22{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:65.2pt;border-top-color:#000000;border-bottom-style:solid}.c28{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:92.2pt;border-top-color:#000000;border-bottom-style:solid}.c0{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:117pt;border-top-color:#000000;border-bottom-style:solid}.c8{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:141.8pt;border-top-color:#000000;border-bottom-style:solid}.c17{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:402.8pt;border-top-color:#000000;border-bottom-style:solid}.c37{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:117pt;border-top-color:#000000;border-bottom-style:solid}.c1{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:117pt;border-top-color:#000000;border-bottom-style:solid}.c7{background-color:#ffffff;margin-left:36pt;padding-top:12pt;padding-left:0pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c13{margin-left:36pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c26{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c11{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c33{padding-top:16pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c2{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Times New Roman";font-style:normal}.c27{padding-top:12pt;text-indent:36pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c3{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Times New Roman";font-style:normal}.c14{background-color:#ffffff;padding-top:12pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c16{-webkit-text-decoration-skip:none;color:#000000;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-style:normal}.c5{padding-top:12pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:right}.c4{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c21{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c20{padding-top:12pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c10{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c29{border-spacing:0;border-collapse:collapse;margin-right:auto}.c24{color:#434343;text-decoration:none;vertical-align:baseline;font-style:normal}.c6{font-size:12pt;font-family:"Times New Roman";font-weight:400}.c35{font-weight:400;font-size:14pt;font-family:"Arial"}.c23{font-size:12pt;font-family:"Times New Roman";font-weight:700}.c31{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c25{-webkit-text-decoration-skip:none;text-decoration:underline;text-decoration-skip-ink:none}.c36{color:#000000;text-decoration:none;vertical-align:baseline}.c15{padding:0;margin:0}.c9{border:1px solid black;margin:5px}.c19{color:inherit;text-decoration:inherit}.c38{height:11pt}.c12{height:0pt}.c18{font-style:italic}.c34{page-break-after:avoid}.c30{text-indent:36pt}.c32{color:#1155cc}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c31 doc-content"><h3 class="c33" id="h.mdi9jjkq9r03"><span>Introduction/Background</span></h3><p class="c21"><span class="c6">Our project will cover genre classification in the music industry, based on the features extracted from the audio files of songs with explicit genre labels. The </span><span class="c6 c25 c32"><a class="c19" href="https://www.google.com/url?q=https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification&amp;sa=D&amp;source=editors&amp;ust=1712101756501770&amp;usg=AOvVaw0ECg9LAzQ3Dow7qbJY9Za7">GTZAN dataset</a></span><span class="c3">&nbsp;contains the following for each song in the 1000-song dataset of 10 genres:</span></p><ul class="c15 lst-kix_tdvx3axora8l-0 start"><li class="c13 li-bullet-0"><span class="c3">Raw audio files (.wav) </span></li><li class="c13 li-bullet-0"><span class="c3">Mel-Spectrogram representations </span></li><li class="c13 li-bullet-0"><span class="c3">.csv containing features extracted from the audio files, and the song&#39;s genre label (57 features per song).</span></li></ul><p class="c11"><span class="c3"></span></p><p class="c21"><span class="c3">Research for genre classification in the music industry has seen many major publications, with one approach highlighting the importance of combining preprocessing techniques and feature extraction (e.g. normalization, MFCCs, UWT, and LPCCs) with various traditional ML algorithms (KNN, SVM, ANN) [1]. More recent research emphasizes the transition from traditional feature engineering towards end-to-end learning models, along with the need for models that can be generalized across a variety of musical pieces, thereby introducing deep learning approaches such as CNN and RNN [2,3]. </span></p><p class="c11"><span class="c3"></span></p><h3 class="c33" id="h.qwkzbuiyfmeu"><span class="c24 c35">Problem Definition</span></h3><p class="c21"><span class="c3">Manual tagging of songs by genre is flawed, but a new tagging system that uses machine learning to classify the genre of songs could address the following shortcomings: </span></p><ul class="c15 lst-kix_nvsh1jp4hufk-0 start"><li class="c13 li-bullet-0"><span class="c23">Scalability/efficiency:</span><span class="c3">&nbsp;Automating genre classification would save music distribution companies time and resources.</span></li></ul><ul class="c15 lst-kix_tbtkw0ll1bh6-0 start"><li class="c13 li-bullet-0"><span class="c23">Consistency and objectivity:</span><span class="c3">&nbsp;Humans are prone to bias, whereas machine learning would apply consistent criteria to all songs. </span></li><li class="c13 li-bullet-0"><span class="c23">G</span><span class="c23">enre</span><span class="c23">&nbsp;equality:</span><span class="c3">&nbsp;Machine learning models can impartially identify emerging genres, giving equal visibility to upcoming artists not fitting traditional genres. </span></li><li class="c13 li-bullet-0"><span class="c23">Discovery/Recommendations: </span><span class="c6">More accurate categorization of music enhances music recommendation systems.</span></li></ul><h3 class="c33" id="h.km25e49esdt1"><span class="c24 c35">Methods</span></h3><p class="c21"><span class="c3">Data Preprocessing Methods:</span></p><ul class="c15 lst-kix_w5w7l1qd8d42-0 start"><li class="c13 li-bullet-0"><span class="c3">PCA: To mitigate the risk of overfitting (due to 57 features), we will produce a reduced-dimension version of the data.</span></li><li class="c13 li-bullet-0"><span class="c3">LDA: Provides an alternative dimensionality reduction method that is suited for maximizing class separation.</span></li><li class="c13 li-bullet-0"><span class="c3">Audio augmentation: By applying pitch/tempo shifting, we can generate augmented versions of the songs for the ML models, improving performance on unseen data.</span></li></ul><p class="c11"><span class="c3"></span></p><p class="c11"><span class="c3"></span></p><p class="c21"><span class="c3">ML Algorithms/Models:</span></p><ul class="c15 lst-kix_b8qdaap7ttdm-0 start"><li class="c13 li-bullet-0"><span class="c3">SVM: Popular for audio classification tasks, particularly due to its performance in high-dimensions.</span></li><li class="c13 li-bullet-0"><span class="c3">RFC: Provides the benefits for classification tasks that decision trees offer, whilst minimizing overfitting.</span></li><li class="c13 li-bullet-0"><span class="c6">Logistic regression: Useful for songs that mix genres (assigns probability of belonging to a specific genre).</span><sup><a href="#cmnt1" id="cmnt_ref1">[a]</a></sup></li><li class="c13 li-bullet-0"><span class="c3">RNN: Cited in the literature as being at the forefront of audio classification tasks (especially when features are extracted from the audio file).</span></li></ul><p class="c11"><span class="c3"></span></p><p class="c21"><span class="c2">Preprocessing Method 1: Audio Augmentation</span></p><p class="c11"><span class="c2"></span></p><p class="c21"><span class="c3">The initial preprocessing method that we will be applying to our data is audio augmentation, which is a beneficial technique frequently used in tasks such as speech recognition, sound classification, and music analysis. The goal of audio augmentation is essentially to apply different augmentations to the original versions of the songs, such that we generate more data points for our models to be trained on. We implemented this method through the augment_audio function (found in &quot;Audio Augmentation.ipynb&quot;) which takes in the time series of the original song, and returns three augmented versions of the song: one with random noise added on top, one with a time stretch, and one with a pitch shift. When we called this function, we used the parameters noise_factor=0.005 (minimal random noise is added), stretch_factor=0.8 (sped up version is returned), and n_steps=-1 (lower pitched version is returned). Since we only have 1,000 original songs, this preprocessing technique helps improve our models&rsquo; performances to unseen data (due to the fact that we now have 4,000 total data points, and the minor differences applied to generate the new data points will help improve classification within the validation set whilst also reducing the risk of overfitting to the training set, since the models are exposed to a wider array of data points).</span></p><p class="c11"><span class="c3"></span></p><p class="c21"><span class="c6">It should be noted that this audio augmentation method will require us to be very careful when performing our train-test split for our model evaluations to ensure that no data leakage occurs. If two versions of the same song are allowed to be assigned to different sides of the train-test split, the models will have falsely accurate performances, since they will recognize that the training set has a very similar song to the one being evaluated within the testing set. This is why within our code, we use the songs&rsquo; predetermined title formatting to our advantage. Each genre has 100 songs, labeled in the format genre.song_number.wav, where song_number is a 5 digit value ranging from 00000 to 00099. We can therefore perform a manual five fold cross-validation, in which the song_numbers act as the index of the train-test split. So for fold one, songs with numbers from 00000 to 00019 will be used as the validation set, whilst songs with numbers from 00020 to 00099 are used as the training set. Not only does this ensure that all four versions of a song remain on the same side of the train-test split for any given fold, but it also implements stratification by making it such that each validation set uses the same number of songs from each genre as its support (ensuring that the evaluation metrics provide a more conclusive and accurate picture of the true performance of the model).</span></p><p class="c14"><span class="c2">Preprocessing Method 2: Principal Component Analysis (PCA)</span></p><p class="c14"><span class="c3">The first dimensionality reduction technique used was PCA. PCA is an unsupervised method that does not use class labels and identifies the principal components of the dataset that capture the maximum variance. This process involves shifting the data onto a new z-space and selecting the top principal components that preserve the largest amount of the variance from the dataset. In our case, PCA was useful given the high dimensionality of our dataset, namely 57 features per sample, as it allowed us to reduce the risk of overfitting our model and reduces the complexity. &nbsp;</span></p><p class="c14"><span class="c3">To implement PCA on our data, we used the &lsquo;PCA&rsquo; module from the &lsquo;sklearn.decomposition&rsquo; package. We wanted to capture a large portion of the variance while still reducing the number of features, and therefore we chose to maintain 95% of the variance of the original dataset which translated to 34 principal components. Note that PCA assumes the directions with the largest variances in our z-space are most informative, which does not necessarily accomplish the best results when the objective is distinguishing between different music genres. This is an area where supervised learning algorithms such as LDA are better for maximizing class separability which is what we see when comparing their results for both SVM and RFC.</span></p><p class="c14"><span class="c23">Preprocessing Method 3: Linear Discriminant Analysis (LDA)</span></p><p class="c14"><span class="c3">While PCA is a very useful dimensionality reduction technique, we wanted to take advantage of the labeled nature of our data during the pre-processing, which is why we also used Linear Discriminant Analysis (LDA) as an alternative dimensionality reduction technique. Unlike PCA, (no class labels required) which shifts the data onto a new z-space that maximizes the amount of variance captured (which may potentially aid in classification tasks by spreading the data out), LDA (class labels required) explicitly optimizes the class separation by shifting the data onto a new z-space that maximizes the ratio of between-class and within-class variance, which subsequently makes the classes more linearly separable. In our case of genre classification, this essentially meant that we are able to reduce the dimensions of our data (and therefore the risk of overfitting) whilst ensuring that we still captured the essence of what separated one genre from another. </span></p><p class="c14"><span class="c6">To apply LDA to our data, we used the &lsquo;LinearDiscriminantAnalysis&rsquo; module from the &lsquo;sklearn.discriminant_analysis package&rsquo;. Unlike PCA, where the number of principal components generated was obtained by stating the proportion of variance we would like our new z-space to capture, LDA requires us to provide it with the number of linear discriminants. Since the maximum number of linear discriminants we can choose is n - 1, where n is the number of classes (in this case 10 genres), we chose to reduce our data to a maximum possible 9 linear discriminants. It should be noted that LDA makes three very significant assumptions about the nature of our data: features are normally distributed, features are statistically independent from one another, and the covariance matrix of our features is constant across classes (homoscedasticity). While it is rare that a data set conforms to all of these assumptions, LDA works very well in practice, as seen through the fact that both our SVM and RFC models achieved their highest accuracies when fed with the LDA formatted version of our data. </span></p><p class="c14 c38"><span class="c2"></span></p><p class="c14"><span class="c2">ML Algorithm/Model 1: Support Vector Machine (SVM)</span></p><p class="c14"><span class="c3">The first classification algorithm that we decided to use is a Support Vector Machine (SVM), due to its many advantages:</span></p><ol class="c15 lst-kix_hd3j599mwgvy-0 start" start="1"><li class="c7 li-bullet-0"><span class="c3">SVM inherently finds the hyperplane that maximizes the margin between different classes, which is especially useful in music classification as some genres only have subtle differences separating them.</span></li><li class="c7 li-bullet-0"><span class="c3">The kernel option provided by the SVM algorithm allows us to tune the model to best fit the characteristics of our data. Through alternating from the default linear kernel to more complicated options such as polynomial or radial basis function (RBF), we can shift our data to a transformed feature space without explicitly needing to compute the coordinates of the new space. Essentially, this allows us to capture non-linear relationships between our audio features, which was evident in our case as the RBF kernel yielded the highest cross-validation accuracy.</span></li><li class="c7 li-bullet-0"><span class="c3">SVM is very well-suited to high-dimensional spaces. While we were able to reduce the number of dimensions down to 34 principal components with PCA and 9 linear discriminants with LDA, being able to use an algorithm that performs relatively well with all 57 original features is advantageous, as it would allow us to maintain some model interpretability (i.e. know which features are more important than others in genre classification).</span></li><li class="c7 li-bullet-0"><span class="c3">While SVM is inherently a binary classifier, it can be used for multi-class classification tasks by using the one-vs-all or one-vs-one extension methods, which is required in our case since we have 10 classes.</span></li></ol><p class="c14"><span class="c2">ML Algorithm/Model 2: Random Forest Classifier (RFC)</span></p><p class="c14"><span class="c3">The second classification algorithm that we decided to use is Random Forest Classifier (RFC), due to its many advantages:</span></p><ol class="c15 lst-kix_8imvyvbshr1d-0 start" start="1"><li class="c7 li-bullet-0"><span class="c3">Because of the relatively simple structure of Random Forests (a collection of decision trees), it is easy to identify important audio features when it comes to genre classification. The decision tree layout actively quantifies how effective certain features are in the prediction process.</span></li><li class="c7 li-bullet-0"><span class="c3">RFC is great at dealing with non-linear relationships because it is an ensemble method (RFC merges results from multiple decision trees). Due to the nature of audio data, we didn&rsquo;t expect our features to be linear, so random forest was a clear choice. </span></li><li class="c7 li-bullet-0"><span class="c3">Again, because RFC is an ensemble method, it is far less likely to overfit the data as compared to a traditional decision tree algorithm. Since we are looking at the aggregation of several decision trees, it is much harder to overfit to the training data (a computed average is much more representative of a dataset than individual point).</span></li><li class="c7 li-bullet-0"><span class="c3">If a RFC is able to learn your data and perform relatively well, it indicates that the data itself is learnable, and thereby encourages the pursuit of deep learning methods.</span></li></ol><h3 class="c33" id="h.n5j6u1cas0w9"><span>Results and Discussion</span></h3><p class="c21"><span class="c3">With our project being based around classification problem with 10 classes, the following metrics will be used (with the goal values):</span></p><ul class="c15 lst-kix_k8ew8v9e5c7-0 start"><li class="c13 li-bullet-0"><span class="c3">Overall accuracy/Cross-validation accuracy (&gt; 70%)</span></li><li class="c13 li-bullet-0"><span class="c3">Precision (&gt; 0.7) (Per-class/averaged)</span></li><li class="c13 li-bullet-0"><span class="c3">Recall (&gt; 0.7) &nbsp;(Per-class/averaged)</span></li><li class="c13 li-bullet-0"><span class="c3">F1 Score (&gt; 0.7) &nbsp;(Per-class/averaged)</span></li></ul><p class="c21"><span class="c6">While we hope that we can achieve 70% and above in these metrics (which are cited as good metric levels for 10 classes), we expect that some classes will have lower metric levels (particularly similar genres that will get misidentified for one another, i.e. pop and hip-hop). This is why we will also use the 10x10 confusion matrix to detect these specific misidentifications.</span></p><p class="c20"><span class="c2">Results</span></p><p class="c20"><span class="c3">We apply both models, SVM and RFC, across the three different data preprocessing types to see which would be most effective for our task. We find the following:</span></p><a id="t.2bd1a2a7b06cfde1457068f9ff67c1014bd735b2"></a><a id="t.0"></a><table class="c29"><tr class="c12"><td class="c37" colspan="1" rowspan="1"><p class="c10"><span class="c16 c23">Avg. Accuracy (%)</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c10"><span class="c2">Original (no dimension reduction)</span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c10"><span class="c2">PCA</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c10"><span class="c2">LDA</span></p></td></tr><tr class="c12"><td class="c37" colspan="1" rowspan="1"><p class="c10"><span class="c2">SVM</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c10"><span class="c3">60.523</span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c10"><span class="c3">58.219</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c10"><span class="c16 c6">70.117</span></p></td></tr><tr class="c12"><td class="c37" colspan="1" rowspan="1"><p class="c10"><span class="c2">RFC</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c10"><span class="c3">58.027</span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c10"><span class="c3">56.168</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c10"><span class="c6 c16">69.351</span></p></td></tr></table><p class="c5"><span class="c6 c25 c18">Table 1</span><span class="c23 c18">: </span><span class="c6 c18 c36">Average accuracy across models / pre-processing techniques </span></p><p class="c20"><span class="c3">We observe that the two highest performing models were SVM with LDA and RFC with LDA. We then look at the accuracy reports and confusion matrices for these two models.</span></p><p class="c20"><span class="c23">Results Algorithm/Model 1: SVM with LDA</span></p><a id="t.bb557876b701ba13a25125268a0d839914321b84"></a><a id="t.1"></a><table class="c29"><tr class="c12"><td class="c1" colspan="1" rowspan="1"><p class="c4"><span class="c16 c23">Genre</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c4"><span class="c16 c23">Precision</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c4"><span class="c16 c23">Recall</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c4"><span class="c16 c23">F1-Score</span></p></td></tr><tr class="c12"><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c2">Blues</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">68.138%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">61.071%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">64.197%</span></p></td></tr><tr class="c12"><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c2">Classical</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">92.185%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">93.810%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">92.401%</span></p></td></tr><tr class="c12"><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c2">Country</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">63.751%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">68.690%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">65.580%</span></p></td></tr><tr class="c12"><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c2">Disco</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">61.338%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">65.155%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">62.431%</span></p></td></tr><tr class="c12"><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c2">HipHop</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">66.044%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">66.024%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">65.035%</span></p></td></tr><tr class="c12"><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c2">Jazz</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">82.460%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">85.702%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">83.714%</span></p></td></tr><tr class="c12"><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c2">Metal</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">78.184%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">78.333%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">77.768%</span></p></td></tr><tr class="c12"><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c2">Pop</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">81.880%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">76.690%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">78.805%</span></p></td></tr><tr class="c12"><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c2">Reggae</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">61.923%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">62.702%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">61.375%</span></p></td></tr><tr class="c12"><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c2">Rock</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">47.108%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">42.988%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">43.913%</span></p></td></tr></table><p class="c5"><span class="c6 c25 c18">Table 2</span><span class="c6 c36 c18">: Accuracy report for SVM with LDA</span></p><p class="c20"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 472.00px;"><img alt="" src="images/image3.png" style="width: 624.00px; height: 472.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span class="c6 c25 c18">Table 3</span><span class="c6 c36 c18">: Confusion matrix of SVM with LDA</span></p><p class="c20"><span class="c23">Results Algorithm/Model 2: RFC with LDA</span></p><a id="t.f218f32e9c7b5cefd1efef5462c03c0d2a7d764e"></a><a id="t.2"></a><table class="c29"><tr class="c12"><td class="c1" colspan="1" rowspan="1"><p class="c4"><span class="c16 c23">Genre</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c4"><span class="c16 c23">Precision</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c4"><span class="c16 c23">Recall</span></p></td><td class="c1" colspan="1" rowspan="1"><p class="c4"><span class="c16 c23">F1-Score</span></p></td></tr><tr class="c12"><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c2">Blues</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">66.723%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">63.417%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">64.926%</span></p></td></tr><tr class="c12"><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c2">Classical</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">93.898%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">90.476%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">91.238%</span></p></td></tr><tr class="c12"><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c2">Country</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">64.734%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">70.393%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">66.969%</span></p></td></tr><tr class="c12"><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c2">Disco</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">59.506%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">61.833%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">60.140%</span></p></td></tr><tr class="c12"><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c2">HipHop</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">64.892%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">61.619%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">62.447%</span></p></td></tr><tr class="c12"><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c2">Jazz</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">78.692%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">84.821%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">81.103%</span></p></td></tr><tr class="c12"><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c2">Metal</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">79.770%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">81.726%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">80.303%</span></p></td></tr><tr class="c12"><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c2">Pop</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">81.868%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">77.440%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">79.000%</span></p></td></tr><tr class="c12"><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c2">Reggae</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">57.213%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">60.762%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">58.133%</span></p></td></tr><tr class="c12"><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c2">Rock</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">49.074%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">41.024%</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c4"><span class="c3">43.886%</span></p></td></tr></table><p class="c5"><span class="c6 c18 c25">Table 4</span><span class="c6 c36 c18">: Accuracy report for RFC with LDA</span></p><p class="c20"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 472.00px;"><img alt="" src="images/image1.png" style="width: 624.00px; height: 472.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span class="c6 c25 c18">Table 5</span><span class="c6 c18">: Confusion matrix of RFC with LDA</span></p><p class="c20"><span class="c2">Discussion of Results</span></p><p class="c20"><span class="c3">When looking at the average accuracy of the models across the three different data pre-processing techniques (Table 1), we find two key observations:</span></p><p class="c27"><span class="c3">1. Our first observation is that PCA worsened both our models and LDA improved both our models. We initially believed this had to do with our threshold for PCA. We set PCA to have a threshold of capturing 90% of the variance in the data (with 23 components), but after changing it to 95% (with 34 components), we obtained the results above. The results above are better than the original results, but still maintain the observation that PCA worsened performance on both models, suggesting that PCA is not the right pre-processing technique for this dataset.</span></p><p class="c27"><span class="c3">There are several possible reasons for this, but we suspect it has to do with reducing data with respect to separability. PCA tries to reduce dimensionality by finding principal components that maximize variance in the dataset. This means that PCA tries to reduce the amount of data while keeping it as representative as possible, but doesn&rsquo;t necessarily help with class separability. It may be that the variance in our data doesn&rsquo;t tend to lead to distinctions, so PCA would reduce the dataset to dimensions that makes classes seem more similar, leading to worsened performance. On the other hand, LDA tries to reduce dimensionality while maintaining class separability. By maximizing the ratio of between-class variance to within-class variance, LDA ensures that the reduced dimensions are effective for class separation. Because our task is classification and we have labeled training data, it makes sense that we use LDA and that it performs better, as its purpose aligns better with our goals.</span></p><p class="c20 c30"><span class="c3">2. Our second observation is that SVM performed better than RFC for all pre-processing techniques. We believe that this is due to the characteristics of our data. Both SVM and RFC work well with non-linear data; however, SVM works better when the data and therefore the decisions are more complex.</span></p><p class="c20"><span class="c3">The confusion matrices above highlight specifically which genres are easy or difficult to label. As you can see, Classical, Jazz, and Metal all have over an 80% accuracy in predicting their respective genres for both SVM and RFC with LDA. You can also see from both models rock was by far the hardest genre to identify (43% and 41%). Through the SVM/LDA combination, we have met our original quantitative goal of achieving an average cross-validation accuracy of 70% and above, but the confusion matrix reinforces our original hypothesis that certain genres were going to be more difficult to differentiate than others.</span></p><p class="c20"><span class="c2">Next Steps</span></p><p class="c20"><span class="c3">Thus far, we have shown the application of non-deep learning methods for music genre classification. Specifically, through the use of LDA with SVM and RFC which yielded promising results with accuracies as high as 70%. The scores from these models demonstrate the learnability of our dataset and their effectiveness in classifying music genres. Moving forward, we want to explore the findings of the cited paper &ldquo;Deep learning for audio-based music classification and tagging,&rdquo; to explore deep learning models such as ANN and RNN to further increase our classification accuracy. </span></p><p class="c20"><span class="c3">For results, we want to include more visualizations on &nbsp;avg. accuracy over folds for SVM/RFC and loss over epochs for ANN/RNN in our final paper. This would allow us to have more insight into the training process as opposed to just looking at the final results. With these visualizations, we can explore the deviation between training and validation to evaluate performance, and whether the model overfits or underfits.</span></p><h3 class="c20 c34" id="h.qq27h8hwvtc7"><span class="c24 c35">References</span></h3><p class="c20"><span class="c6">[1] M. Chaudhury, A. Karami, and M. A. Ghazanfar, &ldquo;Large-scale music genre analysis and classification using Machine Learning with apache spark,&rdquo; </span><span class="c6 c18">Electronics</span><span class="c3">, vol. 11, no. 16, p. 2567, Aug. 2022. doi:10.3390/electronics11162567 </span></p><p class="c20"><span class="c6">[2] J. Nam, K. Choi, J. Lee, S.-Y. Chou, and Y.-H. Yang, &ldquo;Deep learning for audio-based music classification and tagging: Teaching computers to distinguish rock from Bach,&rdquo; </span><span class="c6 c18">IEEE Signal Processing Magazine</span><span class="c3">, vol. 36, no. 1, pp. 41&ndash;51, Dec. 2018. doi:10.1109/msp.2018.2874383 </span></p><p class="c20"><span class="c6">[3] H. Purwins </span><span class="c6 c18">et al.</span><span class="c6">, &ldquo;Deep Learning for Audio Signal Processing,&rdquo; </span><span class="c6 c18">IEEE Journal of Selected Topics in Signal Processing</span><span class="c3">, vol. 13, no. 2, pp. 206&ndash;219, May 2019. doi:10.1109/jstsp.2019.2908700 </span></p><hr style="page-break-before:always;display:none;"><p class="c20 c38"><span class="c3"></span></p><p class="c20"><span class="c2">Gantt Chart</span></p><p class="c20"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 417.00px; height: 522.00px;"><img alt="" src="images/image2.png" style="width: 427.00px; height: 522.00px; margin-left: -3.50px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><sup><a href="#cmnt2" id="cmnt_ref2">[b]</a></sup></p><p class="c20"><span class="c2">Contribution Table</span></p><a id="t.3f44fa04341cea6f7924654b18c6b81976757379"></a><a id="t.3"></a><table class="c29"><tr class="c12"><td class="c22" colspan="1" rowspan="1"><p class="c10"><span class="c2">Name</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c10"><span class="c2">Midterm contributions</span></p></td></tr><tr class="c12"><td class="c22" colspan="1" rowspan="1"><p class="c10"><span class="c3">Ariya</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c10"><span class="c3">RFC implementation, evaluation</span></p></td></tr><tr class="c12"><td class="c22" colspan="1" rowspan="1"><p class="c10"><span class="c3">Akaash</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c10"><span class="c3">Results, visualizations, discussion</span></p></td></tr><tr class="c12"><td class="c22" colspan="1" rowspan="1"><p class="c10"><span class="c3">Dorsa</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c10"><span class="c3">Data Preprocessing (PCA)</span></p></td></tr><tr class="c12"><td class="c22" colspan="1" rowspan="1"><p class="c10"><span class="c3">Nikan</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c10"><span class="c3">Data Preprocessing (LDA), Data Preprocessing (Audio Augmentation)</span></p></td></tr><tr class="c12"><td class="c22" colspan="1" rowspan="1"><p class="c10"><span class="c3">Stella</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c10"><span class="c3">SVM implementation, evaluation</span></p></td></tr></table><p class="c11"><span class="c26"></span></p><div class="c9"><p class="c10"><a href="#cmnt_ref1" id="cmnt1">[a]</a><span class="c26">we need to replace logistic regression with ANN and add a section saying that we had logistic regression listed in our proposal but we are changing because ...</span></p></div><div class="c9"><p class="c10"><a href="#cmnt_ref2" id="cmnt2">[b]</a><span class="c26">Gantt chart contributions arent right, project title is wrong, and it says regression which we replaced with ANN</span></p></div></body></html>